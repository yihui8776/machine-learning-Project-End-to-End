{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:37:43.260329Z",
     "start_time": "2020-04-14T06:37:21.196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/spark/python/pyspark/context.py:123: UserWarning: You are passing in an insecure Py4j gateway.  This presents a security risk, and will be completely forbidden in Spark 3.0\n",
      "  \"You are passing in an insecure Py4j gateway.  This \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name: org.apache.toree.interpreter.broker.BrokerException\n",
       "Message: Py4JJavaError: An error occurred while calling o40.showString.\n",
       ": java.lang.AssertionError: assertion failed: No plan for HiveTableRelation `sparktest`.`student`, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, [id#0, name#1, gender#2, age#3]\n",
       "\n",
       "\tat scala.Predef$.assert(Predef.scala:170)\n",
       "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:93)\n",
       "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2$$anonfun$apply$2.apply(QueryPlanner.scala:78)\n",
       "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2$$anonfun$apply$2.apply(QueryPlanner.scala:75)\n",
       "\tat scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)\n",
       "\tat scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)\n",
       "\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n",
       "\tat scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)\n",
       "\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334)\n",
       "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2.apply(QueryPlanner.scala:75)\n",
       "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2.apply(QueryPlanner.scala:67)\n",
       "\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\n",
       "\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\n",
       "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:93)\n",
       "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2$$anonfun$apply$2.apply(QueryPlanner.scala:78)\n",
       "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2$$anonfun$apply$2.apply(QueryPlanner.scala:75)\n",
       "\tat scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)\n",
       "\tat scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)\n",
       "\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n",
       "\tat scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157)\n",
       "\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334)\n",
       "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2.apply(QueryPlanner.scala:75)\n",
       "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$2.apply(QueryPlanner.scala:67)\n",
       "\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\n",
       "\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\n",
       "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:93)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:73)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:69)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:78)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:78)\n",
       "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3365)\n",
       "\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n",
       "\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n",
       "\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n",
       "\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
       "\tat java.lang.Thread.run(Thread.java:748)\n",
       "\n",
       "(<class 'py4j.protocol.Py4JJavaError'>, Py4JJavaError('An error occurred while calling o40.showString.\\n', JavaObject id=o41), <traceback object at 0x7f221582bf50>)\n",
       "StackTrace: org.apache.toree.interpreter.broker.BrokerState$$anonfun$markFailure$1.apply(BrokerState.scala:163)\n",
       "org.apache.toree.interpreter.broker.BrokerState$$anonfun$markFailure$1.apply(BrokerState.scala:163)\n",
       "scala.Option.foreach(Option.scala:257)\n",
       "org.apache.toree.interpreter.broker.BrokerState.markFailure(BrokerState.scala:162)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "java.lang.reflect.Method.invoke(Method.java:498)\n",
       "py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
       "py4j.Gateway.invoke(Gateway.java:282)\n",
       "py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
       "java.lang.Thread.run(Thread.java:748)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import  SparkConf, SparkContext,SQLContext\n",
    "from pyspark.sql import  SparkSession\n",
    "from pyspark.sql import  HiveContext \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "# 配置参数\n",
    "    #sparkConf=SparkConf()\n",
    " # 实例化\n",
    "    #sc =  SparkContext()\n",
    "    \n",
    "    #初始化spark\n",
    "    #sqlContext =  SQLContext(sparkContext=sc)\n",
    "\n",
    "    spark = SparkSession\\\n",
    "        .builder \\\n",
    "        .appName(\"Spark to Hive\") \\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://129.211.84.214:9083\") \\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    df = spark.read.table(\"sparktest.student\")\n",
    "    df.show()\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T09:51:43.374080Z",
     "start_time": "2020-04-14T09:51:36.887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "|   sparktest|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext \n",
    "from pyspark.sql import HiveContext \n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder \\\n",
    "        .appName(\"Spark to Hive\") \\\n",
    "        .master(\"local\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://129.211.84.214:9083\") \\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "\n",
    "#hive_context = HiveContext(spark)\n",
    "#hive_context.sql('use sparktest')\n",
    "#hive_context.sql('select * from student').show()\n",
    "#spark.sql('select * from student').show()\n",
    "spark.sql(\"show databases\").show()\n",
    "#spark.sql(\"select * from sparktest.student\").show()\n",
    "spark.stop()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-14T14:19:43.319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "|   sparktest|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext \n",
    "from pyspark.sql import HiveContext \n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder \\\n",
    "        .appName(\"Spark to Hive\") \\\n",
    "        .master(\"local\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://129.211.84.214:9083\") \\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "\n",
    "#spark.sql(\"show databases\").show()\n",
    "spark.sql(\"select * from sparktest.student\").show()\n",
    "spark.stop()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache_toree - PySpark",
   "language": "python",
   "name": "apache_toree_pyspark"
  },
  "language_info": {
   "codemirror_mode": "text/x-ipython",
   "file_extension": ".py",
   "mimetype": "text/x-ipython",
   "name": "python",
   "pygments_lexer": "python",
   "version": "3.7.7\n"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
