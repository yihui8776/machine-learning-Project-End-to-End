{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402164, 10)\n",
      "           user  cust_access_net_dt  credit_level  membership_level  gender  birth_date  cust_point  inet_pd_inst_cnt  star_level             label\n",
      "0  train_238138        2.015063e+13          -1.0            9999.0     2.0  19680409.0      9004.0               5.0      1300.0  7C26FADD409BD4B9\n",
      "1    test_17547        2.019031e+13          -1.0            9999.0    -1.0  19780919.0         0.0               4.0      2100.0               NaN\n",
      "2  train_301877        2.006060e+13      100100.0            9999.0     1.0  19451222.0       357.0               4.0      1200.0  7C26FADD409BD4B9\n",
      "3  train_109061        2.014071e+13          -1.0            9999.0     1.0  19730606.0      6272.0               5.0      1500.0  7C26FADD409BD4B9\n",
      "4  train_199787        2.004110e+13          -1.0            9999.0     1.0  19640413.0       988.0               1.0      1400.0  7C26FADD409BD4B9\n",
      "Index(['user', 'cust_access_net_dt', 'credit_level', 'membership_level', 'gender', 'birth_date', 'cust_point', 'inet_pd_inst_cnt', 'star_level', 'label'], dtype='object')\n",
      "       cust_access_net_dt   credit_level  membership_level         gender    birth_date    cust_point  inet_pd_inst_cnt     star_level\n",
      "count        4.012140e+05  401214.000000     401214.000000  401214.000000  3.036450e+05  4.012140e+05     401214.000000  401214.000000\n",
      "mean         2.009649e+13  393273.726513       9917.675577       0.713131  1.980117e+07  6.180001e+03         11.002899    1483.129622\n",
      "std          8.004292e+11  459553.528259        842.604411       1.112398  4.062665e+05  9.582990e+04        204.065105     490.170057\n",
      "min          9.999123e+07      -1.000000       1000.000000      -1.000000  1.899123e+07 -1.323391e+06          0.000000    1100.000000\n",
      "25%          2.011031e+13      -1.000000       9999.000000      -1.000000  1.971012e+07  4.800000e+02          1.000000    1300.000000\n",
      "50%          2.015040e+13  100200.000000       9999.000000       1.000000  1.980091e+07  2.139000e+03          4.000000    1400.000000\n",
      "75%          2.017112e+13  999999.000000       9999.000000       1.000000  1.988091e+07  5.160000e+03          6.000000    1500.000000\n",
      "max          2.019093e+13  999999.000000       9999.000000       2.000000  3.000010e+07  1.562282e+07      34689.000000    9999.000000\n",
      "(402164, 65)\n",
      "(322757, 65)\n",
      "(79407, 65)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\"\"\"\n",
    "数据合并\n",
    "组合为宽表\n",
    "\"\"\"\n",
    "\n",
    "# 保证脚本与Python3兼容\n",
    "from __future__ import print_function\n",
    "\n",
    "import os   #读取数据文件\n",
    "import sys\n",
    "import pymysql \n",
    "from sqlalchemy import create_engine\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split  #划分训练集测试集使用\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "from sklearn.linear_model import LogisticRegression ,LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction import DictVectorizer #特征转换器\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline \n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def readData(path):\n",
    "    \"\"\"\n",
    "    使用pandas读取数据\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path)\n",
    "    cols = list(data.columns.values)\n",
    "    return data[cols]\n",
    " \n",
    "   \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # 设置显示格式\n",
    "    pd.set_option('display.width', 1000)\n",
    "    homePath = os.path.dirname(os.path.abspath('__file__'))\n",
    "    # Windows下的存储路径与Linux并不相同\n",
    "    if os.name == \"nt\":\n",
    "        dataPath = \"%s\\\\cust_data.csv\" % homePath\n",
    "    else:\n",
    "        dataPath = \"%s/cust_data.csv\" % homePath\n",
    "    custdata = readData(dataPath)\n",
    "    \n",
    "    if os.name == \"nt\":\n",
    "        dataPath = \"%s\\\\call_data.csv\" % homePath\n",
    "    else:\n",
    "        dataPath = \"%s/call_data.csv\" % homePath\n",
    "    calldata = readData(dataPath)\n",
    "    \n",
    "    if os.name == \"nt\":\n",
    "        dataPath = \"%s\\\\dpi_data.csv\" % homePath\n",
    "    else:\n",
    "        dataPath = \"%s/dpi_data.csv\" % homePath\n",
    "    dpidata = readData(dataPath)\n",
    "    \n",
    "    if os.name == \"nt\":\n",
    "        dataPath = \"%s\\\\prd_data.csv\" % homePath\n",
    "    else:\n",
    "        dataPath = \"%s/prd_data.csv\" % homePath\n",
    "    prddata = readData(dataPath)\n",
    "    \n",
    "    if os.name == \"nt\":\n",
    "        dataPath = \"%s\\\\trmnl_data.csv\" % homePath\n",
    "    else:\n",
    "        dataPath = \"%s/trmnl_data.csv\" % homePath\n",
    "    trmnldata = readData(dataPath)\n",
    "    \n",
    "    if os.name == \"nt\":\n",
    "        dataPath = \"%s\\\\train_result.csv\" % homePath\n",
    "    else:\n",
    "        dataPath = \"%s/train_result.csv\" % homePath\n",
    "    traindata = readData(dataPath)\n",
    "    \n",
    "    \n",
    "    #连接合并\n",
    "    data1 = pd.merge(custdata,traindata,on='user',how='left')\n",
    "    print(data1.shape)\n",
    "    print(data1.head())\n",
    "    print(data1.columns)\n",
    "    print(data1.describe())\n",
    "   \n",
    "    \n",
    "    data2 = pd.merge(data1,calldata,on='user',how='left')\n",
    "    data3 = pd.merge(data2,dpidata,on='user',how='left')\n",
    "    data4 = pd.merge(data3,prddata,on='user',how='left')\n",
    "    alldata = pd.merge(data4,trmnldata,on='user',how='left')   \n",
    "     \n",
    "    print(alldata.shape)    \n",
    "    #训练和测试标记\n",
    "    train = alldata[alldata['user'].str.contains(\"train\")]\n",
    "    test = alldata[alldata['user'].str.contains(\"test\")]\n",
    "    print(train.shape)  \n",
    "    print(test.shape)\n",
    "    \n",
    "    #保存数据\n",
    "    #训练数据\n",
    "    train.to_csv('train.csv',index=0) \n",
    "    #测试数据\n",
    "    test.to_csv('test.csv',index =0)\n",
    "    #所有数据\n",
    "    alldata.to_csv('all.csv',index=0)\n",
    "    \n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#填补年龄\n",
    "data1=data1.copy()\n",
    "data1['AGE'].fillna(0, inplace=True)  #填补空值\n",
    "data1=data1.copy()\n",
    "data.to_csv('train.csv',header=0,index=0) #不保存列名和索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
